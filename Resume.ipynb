{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cca55cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import docx2txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "db2ec539",
   "metadata": {},
   "outputs": [],
   "source": [
    "jd=docx2txt.process(\"F:\\\\NLP projet\\\\Resume\\\\JD.docx\")\n",
    "resume=docx2txt.process(\"F:\\\\NLP projet\\\\Resume\\\\Resume2.docx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5dad8eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KAVITHA LAKSHMI MATTA\n",
      "\n",
      "Location: Bengaluru, Phone: +91 7095713128,  Email: kavithalakshmimatta28@gmail.com LinkedIn: linkedin.com/in/kavitha-lakshmi-matta, GitHub: github.com/KavithaLakshmi28\n",
      "\n",
      "\n",
      "\n",
      "PROFESSIONAL SUMMARY\n",
      "\n",
      "Results-driven ML Engineer actively transitioning into a full-time Data Analyst role. Strong analytical thinker with a foundation in Python, SQL, Power BI, and Excel. Experienced in data cleaning, exploratory data analysis, KPI tracking, and dashboard design. Passionate about using data to generate business insights. Demonstrated ability to translate technical outputs into stakeholder- friendly reports through hands-on analytics projects.\n",
      "\n",
      "\n",
      "\n",
      "SKILLS\n",
      "\n",
      " Programming: Python, SQL, MATLAB  Data Analysis: Pandas, NumPy, Excel\n",
      "\n",
      " Data Visualization: Power BI, Tableau, Matplotlib, Seaborn  Databases: MongoDB, SQLite\n",
      "\n",
      " Tools & Techniques: Jupyter Notebook, Git, EDA, KPI Tracking\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "WORK EXPERIENCE\n",
      "\n",
      "\tML Engineer, Evalueserve.com\tJan 2024 - Present\n",
      "\n",
      " Collected and prepared large datasets for business analysis through data cleaning, preprocessing, augmentation, and annotation.\n",
      "\n",
      "  Conducted exploratory data analysis (EDA) using Python (Pandas, NumPy) to identify trends, correlations, and outliers in datasets.\n",
      "\n",
      " Evaluated and fine-tuned models to meet defined performance, accuracy, and efficiency standards.\n",
      "\n",
      " Designed, developed, trained, and deployed ML models and AI solutions, including custom chatbots and knowledge-based systems.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "PROJECTS\n",
      "\n",
      "Retail Banking KPI s Trend Analysis\n",
      "\n",
      "\n",
      "\n",
      "Analyzed multi-year French retail banking data to uncover key trends in KPIs like interest margins, total revenue, and product category performance\n",
      "\n",
      "Cleaned, merged, and preprocessed datasets using Pandas and NumPy, handling null values, duplicates, and data type inconsistencies\n",
      "\n",
      "Conducted exploratory data analysis (EDA) to track changes in key indicators and identify top performing financial products\n",
      "\n",
      "Used Matplotlib and Seaborn to create interactive visualizations such as line plots, heatmaps, and categorical comparisons.\n",
      "\n",
      "Delivered actionable business insights used to support strategic financial planning and revenue forecasting\n",
      "\n",
      "\n",
      "\n",
      "Auto-Tagging for Hierarchical Multi-Label Classification\n",
      "\n",
      " ClassificationDeveloped an ML pipeline using Logistic Regression for automatic tagging of documents into33 top-level and 263 sub-level categories\n",
      "\n",
      " Implemented TF-IDF vectorization and feature engineering techniques to boost classification performance\n",
      "\n",
      " Reduced manual tagging effort by 50%, streamlining operations and increasing tagging consistency\n",
      "\n",
      " Tuned model hyperparameters and validated results with precision, recall, and F1-score metrics   Enabled scalable, rule-independent tagging that can be reused across business domainsClaude\n",
      "\n",
      "\n",
      "\n",
      "Context-Aware QsA System with database Integration Using Model Context Protocol\n",
      "\n",
      " Designed a hybrid Q&A framework combining Anthropic's Claude API with SQL (SQLite) and NoSQL (MongoDB) databases\n",
      "\n",
      "  Created a contextual query system that fetches relevant information dynamically based on user input\n",
      "\n",
      " Structured knowledge base entries for high-accuracy answers and improved retrieval performance\n",
      "\n",
      " Developed NLP routines to format questions and interpret Claude’s responses, enabling domain- specific answer flow.\n",
      "\n",
      "\n",
      "\n",
      "HR Analytics Dashboard – Power BI\n",
      "\n",
      " Designed and developed a Power BI dashboard to visualize employee attrition, tenure distribution, department strength, and gender diversity\n",
      "\n",
      "  Integrated Excel and mock HR datasets to create slicers, drill-down visuals, and KPI indicators\n",
      "\n",
      "  Empowered HR stakeholders to explore team health and diversity metrics interactively,improving workforce planning\n",
      "\n",
      "  Utilized DAX functions and measures to customize insights per business needs\n",
      "\n",
      "Tata Cliq Sales Dashboard – Power BI\n",
      "\n",
      " Built a sales performance dashboard using Power BI to analyze regional revenue, product categories, and monthly sales trends\n",
      "\n",
      " Used Power Query Editor for data cleaning and shaping; added calculated columns and KPIs for real-time tracking\n",
      "\n",
      "  Delivered insights through KPI cards, trendlines, pie charts, and interactive filters\n",
      "\n",
      " Helped identify underperforming product lines, leading to targeted marketing and inventory optimization strategies.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "EDUCATION\n",
      "\n",
      " PhD in Statistical Signal Processing\n",
      "\n",
      "Koneru Lakshmaiah Education Foundation (KLEF), Guntur\n",
      "\n",
      "  M.Tech in Computer Science and Engineering\n",
      "\n",
      "NRI Institute of Technology, Agiripalli\n",
      "\n",
      "  B.Tech in Information Technology\n",
      "\n",
      "Sri Sarathi Institute of Technology, Nuzvidu\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ACHIEVEMENTS\n",
      "\n",
      "  Published multiple research papers in signal processing (Google Scholar)\n",
      "\n",
      "  Presented project outcomes at NRB SSB panel workshop and NPOL, Kochi.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "2017- 2023\n",
      "\n",
      "\n",
      "\n",
      "2013-2015\n",
      "\n",
      "\n",
      "\n",
      "2009-2013\n"
     ]
    }
   ],
   "source": [
    "print(resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8ba1fe4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = [jd, resume]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f7b2b5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "match_ = cv.fit_transform(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f5c2e014",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "simi = cosine_similarity(match_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a10f354a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.70612233]\n",
      " [0.70612233 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(simi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2de51e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity of resume with JD: 70.61 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Similarity of resume with JD:\", round(simi[1][0] * 100, 2), \"%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Resume",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
